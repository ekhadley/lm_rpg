from codecs import utf_8_decode
import json
import requests
import copy
import os
from dotenv import load_dotenv

load_dotenv(override=True)

from model_tools import Toolbox

import callbacks
from callbacks import CallbackHandler

from utils import *

class OpenRouterStream:
    """
    Streams responses from OpenRouter. Iteration over the object yields only valid json.
    """
    def __init__(
        self,
        model_name: str,
        messages: list[dict],
        tools: list[dict],
        thinking_enabled: bool,
        thinking_effort: str,
        key: str
    ):
        self.pending_objects = []
        self.response_stream = requests.post(
            url = "https://openrouter.ai/api/v1/chat/completions",
            headers = {
                "Authorization": f"Bearer {key}",
                "Content-Type": "application/json"
            },
            json = {
                "model": model_name,
                "messages": messages,
                "tools": tools,
                "reasoning": {
                    "enabled": thinking_enabled,
                    "effort": thinking_effort if thinking_enabled else None,
                    "exclude": False,
                },
                "stream": True
            },
            stream = True
        )
        if self.response_stream.status_code != 200:
            error_msg = self.response_stream.text.replace("\\n ", "\n ").replace("\\\"", "\"")
            assert self.response_stream.status_code == 200, f"Error response from OpenRouter: {error_msg}"
        self.response_iter = self.response_stream.iter_content(chunk_size=1024, decode_unicode=False)
        
        self.content_stream_finished = False
        self.buffer = ""
        self.decode_retry_count = 0
        self.decode_retry_limit = 1000

    def __iter__(self):
        return self

    def __next__(self) -> dict:
        if self.pending_objects:
            return self.pending_objects.pop(0)

        while True:
            # Ensure we have at least one complete SSE event in the buffer
            def find_event_delimiter(buf: str) -> tuple[int, int]:
                idx_lf = buf.find("\n\n")
                idx_crlf = buf.find("\r\n\r\n")
                if idx_lf == -1 and idx_crlf == -1:
                    return -1, 0
                if idx_lf == -1:
                    return idx_crlf, 4
                if idx_crlf == -1:
                    return idx_lf, 2
                # choose earliest occurrence
                return (idx_lf, 2) if idx_lf < idx_crlf else (idx_crlf, 4)

            while True:
                idx, sep_len = find_event_delimiter(self.buffer)
                if idx != -1:
                    break
                if self.content_stream_finished:
                    break
                try:
                    next_chunk = utf_8_decode(self.response_iter.__next__())[0]
                    self.buffer += next_chunk
                except StopIteration:
                    self.content_stream_finished = True
                    break

            # If stream is finished and buffer is empty or only contains DONE, stop.
            if self.content_stream_finished and (self.buffer.strip() == "" or self.buffer.strip() == "data: [DONE]"):
                raise StopIteration

            # Extract one SSE event (or whatever remains if no delimiter found at end)
            if idx != -1:
                event_chunk = self.buffer[:idx]
                self.buffer = self.buffer[idx + sep_len:]
            else:
                event_chunk = self.buffer
                self.buffer = ""

            if event_chunk.strip() == "":
                # Nothing meaningful in this chunk; continue reading
                continue

            # Parse SSE fields; concatenate multi-line data fields, ignore comments/other fields
            data_lines: list[str] = []
            for raw_line in event_chunk.splitlines():
                line = raw_line.rstrip("\r")
                if not line:
                    continue
                if line.startswith(":"):
                    # SSE comment/keepalive
                    continue
                if line.startswith("data:"):
                    data_lines.append(line[5:].lstrip())
                # Ignore other fields like id:, event:, retry:

            if not data_lines:
                # No data lines in this event; continue
                continue

            data_payload = "\n".join(data_lines).strip()

            if data_payload == "[DONE]":
                # Mark finished; only stop if buffer drained
                self.content_stream_finished = True
                if self.buffer.strip() == "":
                    raise StopIteration
                continue

            try:
                # Attempt to parse one or more JSON objects from the payload
                decoder = json.JSONDecoder()
                pos = 0
                while pos < len(data_payload):
                    # Skip whitespace
                    while pos < len(data_payload) and data_payload[pos].isspace():
                        pos += 1
                    if pos >= len(data_payload):
                        break
                    
                    obj, end = decoder.raw_decode(data_payload, idx=pos)
                    self.pending_objects.append(obj)
                    pos = end

                if self.pending_objects:
                    self.decode_retry_count = 0
                    return self.pending_objects.pop(0)
                
                # If we have content but parsed nothing, raise error to hit retry logic
                if data_payload.strip():
                    raise json.JSONDecodeError("No JSON object found", data_payload, 0)

            except json.JSONDecodeError as e:
                if self.pending_objects:
                    # We parsed some objects but failed on the rest. Return what we have.
                    self.decode_retry_count = 0
                    logger.warning(f"Partial parse success. Discarding tail: {data_payload[pos:]}")
                    return self.pending_objects.pop(0)

                self.decode_retry_count += 1
                if self.decode_retry_count > self.decode_retry_limit or self.content_stream_finished:
                    logger.error(f"({self.decode_retry_count}) [{self.content_stream_finished}] Error decoding data payload: {repr(data_payload)}")
                    logger.error(f"Buffer contents: {repr(self.buffer)}")
                    raise e
                # On transient decode issues, keep accumulating more data
                continue
    
    def close(self):
        self.response_stream.close()
    
    def __del__(self):
        self.close()

class OpenRouterProvider():
    def __init__(
            self,
            model_name: str,
            toolbox: Toolbox,
            system_prompt: str,
            callback_handler: CallbackHandler,
            thinking_effort: str = "high",
            key: str|None = os.getenv("OPENROUTER_API_KEY"),
        ):
        assert key is not None, "OPENROUTER_API_KEY is not set"
        self.key: str = key
        self.model_name: str = model_name
        self.tb: Toolbox = toolbox
        self.tool_schemas = self.tb.getToolSchemas()
        self.system_prompt = system_prompt
        self.messages: list[dict] = []
        self.cb = callback_handler
        self.thinking_enabled = thinking_effort != "none"
        self.thinking_effort = thinking_effort
        self.usage_history: list[dict] = []  # Track usage per turn
        
        self.addSystemMessage(system_prompt)
    
    def getCostStats(self) -> dict:
        """Calculate cost statistics from usage history"""
        if not self.usage_history:
            return {
                "total_tokens": 0,
                "total_cost": 0.0,
                "avg_tokens_per_turn": 0,
                "avg_cost_per_turn": 0.0,
                "turn_count": 0
            }
        
        total_tokens = sum(u.get("total_tokens", 0) for u in self.usage_history)
        total_cost = sum(u.get("cost", 0.0) for u in self.usage_history)
        turn_count = len(self.usage_history)
        
        return {
            "total_tokens": total_tokens,
            "total_cost": total_cost,
            "avg_tokens_per_turn": total_tokens // turn_count if turn_count > 0 else 0,
            "avg_cost_per_turn": total_cost / turn_count if turn_count > 0 else 0.0,
            "turn_count": turn_count
        }

    def addSystemMessage(self, content: str) -> None:
        self.messages.insert(0, {
            "role": "system",
            "content": content,
        })
    def addUserMessage(self, content: str) -> None:
        self.messages.append({
            "role": "user",
            "content": content,
        })
    def addAssistantMessage(self, content) -> None:
        self.messages.append({
            "role": "assistant",
            "content": content,
        })
    def saveMessages(self, path: str, **kwargs) -> None:
        with open(path, "w+") as f:
            json.dump({
                "model_name": kwargs.get("model_name", self.model_name),
                "system_name": kwargs.get("system_name", ""),
                "messages": self.messages,
            }, f, indent=4)
    def loadMessages(self, path: str) -> list[dict] | None:
        if os.path.exists(path):
            with open(path) as f:
                data = json.load(f)
                if "messages" in data:
                    messages = data["messages"]
                    self.messages = messages
                    
                    # Reconstruct usage_history from per-message usage data
                    self.usage_history = []
                    for msg in messages:
                        if msg.get("role") == "assistant" and "usage" in msg:
                            self.usage_history.append(msg["usage"])
                    
                    return messages
        return None

    def getStream(self) -> OpenRouterStream:
        return OpenRouterStream(
            model_name = self.model_name,
            messages = self.messages,
            tools = self.tool_schemas,
            thinking_enabled = self.thinking_enabled,
            thinking_effort = self.thinking_effort,
            key = self.key
        )

    def run(self) -> None:
        currently_outputting_text = False
        pending_tool_calls = False
        finish_reason = None
        stream = self.getStream()
        
        for event in stream:
            # Capture usage from the final chunk (comes after finish_reason)
            usage = event.get("usage")
            if usage:
                self.messages[-1]["usage"] = usage
                self.usage_history.append(usage)
            
            # Skip events without choices (e.g., usage-only final chunks)
            choices = event.get("choices", [])
            if not choices:
                continue
            
            event_item = choices[0]
            delta = event_item.get("delta", {})
            if not delta:
                continue
            
            # Initialize assistant message on first delta
            if self.messages[-1]["role"] != "assistant":
                self.messages.append(copy.deepcopy(delta))
                if "tool_calls" in delta:
                    self.messages[-1]["tool_calls"] = []
                self.messages[-1]["reasoning"] = ""
                self.messages[-1]["reasoning_details"] = [{}]

            # Handle text content
            delta_content = delta.get("content")
            if delta_content:
                self.messages[-1]["content"] += delta_content
                if not currently_outputting_text:
                    currently_outputting_text = True
                self.cb.text_output(text=delta_content)
            
            # Handle reasoning (supports multiple formats)
            # Anthropic models send reasoning in both delta.reasoning AND delta.reasoning_details
            # We must use one OR the other, not both, to avoid duplication
            reasoning_delta = None
            reasoning_details = delta.get("reasoning_details", [])
            
            if reasoning_details and isinstance(reasoning_details, list):
                for detail in reasoning_details:
                    if isinstance(detail, dict):
                        detail_text = detail.get("text")
                        if detail_text:
                            reasoning_delta = (reasoning_delta or "") + detail_text
                        elif detail.get("type") == "reasoning.summary":
                            summary = detail.get("summary")
                            if summary:
                                reasoning_delta = (reasoning_delta or "") + summary
                
                if reasoning_details != [{}]:
                    self.messages[-1]["reasoning_details"] = reasoning_details
            
            # Only fall back to delta.reasoning if reasoning_details didn't provide content
            if reasoning_delta is None:
                reasoning_delta = delta.get("reasoning")
            
            if reasoning_delta:
                self.messages[-1]["reasoning"] += reasoning_delta
                self.cb.think_output(text=reasoning_delta)

            # Handle tool calls
            tool_calls = delta.get("tool_calls", [])
            for tool_call in tool_calls:
                if "id" in tool_call:
                    if "tool_calls" not in self.messages[-1]:
                        self.messages[-1]["tool_calls"] = []
                    self.messages[-1]["tool_calls"].append(tool_call)
                    self.cb.tool_request(name=tool_call["function"]["name"], inputs={})
                self.messages[-1]["tool_calls"][-1]["function"]["arguments"] += tool_call["function"]["arguments"]
            
            # Handle finish reasons
            finish_reason = event_item.get("finish_reason")
            if finish_reason == "stop":
                currently_outputting_text = False
                # Check for non-streamed reasoning in final message
                final_reasoning = event_item.get("message", {}).get("reasoning") or delta.get("reasoning")
                if final_reasoning and not self.messages[-1].get("reasoning"):
                    self.messages[-1]["reasoning"] = final_reasoning
                    self.cb.think_output(text=final_reasoning)
                continue  # Continue to catch usage chunk
            
            if finish_reason == "tool_calls":
                pending_tool_calls = True
                continue  # Continue to catch usage chunk
            
        # Process pending tool calls after stream ends
        if pending_tool_calls:
            for tool_call in self.messages[-1]["tool_calls"]:
                tool_name = tool_call["function"]["name"]
                tool_arguments = tool_call["function"]["arguments"]
                call_id = tool_call["id"]
                
                tool_result = self.tb.getToolResult(tool_name, tool_arguments)
                self.submitToolOutput(call_id, tool_result)
                
                parsed_arguments = tool_arguments
                if isinstance(tool_arguments, str) and tool_arguments:
                    try:
                        parsed_arguments = json.loads(tool_arguments)
                    except json.JSONDecodeError:
                        pass
                
                self.cb.tool_submit(names=[tool_name], inputs=[parsed_arguments], results=[tool_result])

            self.run()
            return

        stream.close()
        self.cb.turn_end(cost_stats=self.getCostStats(), finish_reason=finish_reason)

    def submitToolCall(self, tool_name: str, tool_arguments: dict, tool_call_id: str) -> None:
        self.messages.append({
            "role": "tool",
            "tool_call_id": tool_call_id,
            "arguments": tool_arguments,
        })
    def submitToolOutput(self, call_id: str, tool_output: str) -> None:
        self.messages.append({
            "role": "tool",
            "tool_call_id": call_id,
            "content": tool_output,
        })
    

